{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client():\n",
    "    client = weaviate.Client(\"http://localhost:8080\")\n",
    "    meta_info = client.get_meta()\n",
    "    print(meta_info)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contextionaryVersion': 'en0.16.0-v0.4.19', 'contextionaryWordCount': 818107, 'hostname': 'http://[::]:8080', 'version': '0.22.15'}\n"
     ]
    }
   ],
   "source": [
    "client = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxanomy():\n",
    "    ## load taxonomy from https://arxiv.org/category_taxonomy\n",
    "    website_url = requests.get('https://arxiv.org/category_taxonomy').text\n",
    "    soup = BeautifulSoup(website_url,'lxml')\n",
    "\n",
    "    root = soup.find('div',{'id':'category_taxonomy_list'})\n",
    "\n",
    "    tags = root.find_all([\"h2\",\"h3\",\"h4\",\"p\"], recursive=True)\n",
    "\n",
    "    level_1_name = \"\"\n",
    "    level_2_code = \"\"\n",
    "    level_2_name = \"\"\n",
    "\n",
    "    level_1_names = []\n",
    "    level_2_codes = []\n",
    "    level_2_names = []\n",
    "    level_3_codes = []\n",
    "    level_3_names = []\n",
    "    level_3_notes = []\n",
    "\n",
    "    for t in tags:\n",
    "        if t.name == \"h2\":\n",
    "            level_1_name = t.text    \n",
    "            level_2_code = t.text\n",
    "            level_2_name = t.text\n",
    "        elif t.name == \"h3\":\n",
    "            raw = t.text\n",
    "            level_2_code = re.sub(r\"(.*)\\((.*)\\)\",r\"\\2\",raw)\n",
    "            level_2_name = re.sub(r\"(.*)\\((.*)\\)\",r\"\\1\",raw)\n",
    "        elif t.name == \"h4\":\n",
    "            raw = t.text\n",
    "            level_3_code = re.sub(r\"(.*) \\((.*)\\)\",r\"\\1\",raw)\n",
    "            level_3_name = re.sub(r\"(.*) \\((.*)\\)\",r\"\\2\",raw)\n",
    "        elif t.name == \"p\":\n",
    "            notes = t.text\n",
    "            level_1_names.append(level_1_name)\n",
    "            level_2_names.append(level_2_name)\n",
    "            level_2_codes.append(level_2_code)\n",
    "            level_3_names.append(level_3_name)\n",
    "            level_3_codes.append(level_3_code)\n",
    "            level_3_notes.append(notes)\n",
    "\n",
    "    df_taxonomy = pd.DataFrame({\n",
    "        'group_name' : level_1_names,\n",
    "        'archive_name' : level_2_names,\n",
    "        'archive_id' : level_2_codes,\n",
    "        'category_name' : level_3_names,\n",
    "        'category_id' : level_3_codes,\n",
    "        'category_description': level_3_notes\n",
    "\n",
    "    })\n",
    "    #df_taxonomy.to_csv(\"arxiv-metadata-ext-taxonomy.csv\", index=False)\n",
    "    #df_taxonomy.groupby([\"group_name\",\"archive_name\"]).head(3)\n",
    "\n",
    "    groups = [] # {name}\n",
    "    archives = [] # {name, id, inGroup}\n",
    "    categories = [] # {name, id, description, inArchive}\n",
    "\n",
    "    group_names = list(set(level_1_names))\n",
    "    for name in group_names:\n",
    "        groups.append({\"name\": name})\n",
    "\n",
    "    df_archives = pd.DataFrame({\n",
    "        'inGroup' : level_1_names,\n",
    "        'name' : level_2_names,\n",
    "        'id' : level_2_codes\n",
    "\n",
    "    })\n",
    "    df_archives.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    archives = df_archives.to_dict(orient=\"records\")\n",
    "\n",
    "    df_categories = pd.DataFrame({\n",
    "        'inArchive' : level_2_names,\n",
    "        'name' : level_3_names,\n",
    "        'id' : level_3_codes,\n",
    "        'description' : level_3_notes\n",
    "    })\n",
    "    df_categories.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    categories = df_categories.to_dict(orient=\"records\")\n",
    "    \n",
    "    return groups, archives, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups, archives, categories = load_taxanomy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Electrical Engineering and Systems Science'}, {'name': 'Statistics'}, {'name': 'Mathematics'}, {'name': 'Computer Science'}, {'name': 'Quantitative Finance'}, {'name': 'Economics'}, {'name': 'Physics'}, {'name': 'Quantitative Biology'}]\n"
     ]
    }
   ],
   "source": [
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_groups(groups):\n",
    "    # add groups to weaviate\n",
    "    batch = weaviate.ThingsBatchRequest()\n",
    "    for group in groups:\n",
    "        batch.add_thing(group, \"Group\")\n",
    "    client.batch.create_things(batch)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_groups(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_of_groups():\n",
    "    # get ids of groups\n",
    "    groups_with_uuids = client.query.get.things(\"Group\", [\"name\", \"uuid\"]).do()\n",
    "    groups_with_uuids = groups_with_uuids['data']['Get']['Things']['Group']\n",
    "    groups_with_uuids_dict = {}\n",
    "    for group in groups_with_uuids:\n",
    "        groups_with_uuids_dict[group['name']] = group['uuid']\n",
    "    return groups_with_uuids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Statistics': '2d2182cd-b0e7-4683-bddc-48e1d8d5e2c8', 'Mathematics': '5da91aea-ad85-4aa2-bb93-32736144eda5', 'Quantitative Finance': '4e66509a-bb8f-4b54-a774-cfa2267cddd4', 'Electrical Engineering and Systems Science': '02335df5-e332-486b-8206-1ac3cdd347a2', 'Computer Science': 'bec10552-ad8a-4b10-a4e9-4968683be506', 'Physics': 'e4487feb-d0a9-4191-858c-2b17c24c3ddd', 'Economics': '0c40d4d2-55ed-4183-874e-9ff7875c3545', 'Quantitative Biology': 'b08e86e6-c838-4771-ba9b-c3bf234814ac'}\n"
     ]
    }
   ],
   "source": [
    "groups_with_uuids_dict = get_ids_of_groups()\n",
    "print(groups_with_uuids_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_archives(archives):\n",
    "    groups_with_uuids_dict = get_ids_of_groups()\n",
    "    # add archives to weaviate\n",
    "    batch = weaviate.ThingsBatchRequest()\n",
    "\n",
    "    archives_copy = archives\n",
    "    for archive in archives_copy:\n",
    "        group_beacon = \"weaviate://localhost/things/\" + groups_with_uuids_dict[archive['inGroup']]\n",
    "        archive['inGroup'] = [{\n",
    "            \"beacon\": group_beacon\n",
    "        }]\n",
    "        batch.add_thing(archive, \"Archive\")\n",
    "\n",
    "    client.batch.create_things(batch)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_archives(archives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_of_archives():\n",
    "    # get ids of archives\n",
    "    archives_with_uuids = client.query.get.things(\"Archive\", [\"name\", \"uuid\"]).do()\n",
    "    archives_with_uuids = archives_with_uuids['data']['Get']['Things']['Archive']\n",
    "    archives_with_uuids_dict = {}\n",
    "    for archive in archives_with_uuids:\n",
    "        archives_with_uuids_dict[archive['name']] = archive['uuid']\n",
    "    return archives_with_uuids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Astrophysics': '4601a64f-70bd-4c3b-a233-a8d361f0ca16', 'Condensed Matter': 'dae7dc58-ad3c-4088-8599-dff2743103e7', 'High Energy Physics - Experiment': '97395fa3-ba03-442e-b5bb-4085a6c9aef2', 'High Energy Physics - Lattice': 'baff8c08-2697-4746-806a-c4ebda31c28c', 'Nonlinear Sciences': 'f50513e3-aaf3-4eba-b3e7-244bf837e0d2', 'Nuclear Theory': '3e961d27-97e0-4040-ac02-98eb63f30097', 'Computer Science': '3132ccf1-f42b-48d1-890c-46a1b8d8b42c', 'Economics': '1d888fff-0838-43b1-9012-9b13d8664e33', 'Mathematics': 'a96afcaf-2d7c-4030-83b2-ff66f267adbd', 'Nuclear Experiment': 'd332032c-701d-4496-b72e-5ba13fde4c70', 'Electrical Engineering and Systems Science': '0525119c-8de5-485f-bc94-bf7c7398b99f', 'General Relativity and Quantum Cosmology': '2ebefcbd-a7a3-457d-bfd4-18711348afc8', 'High Energy Physics - Phenomenology': '2ecfcf64-577e-43aa-ac77-175e2626f526', 'High Energy Physics - Theory': '68845139-0599-49db-bb19-861de7e20084', 'Mathematical Physics': '0e598c6c-3e6e-415d-b89e-4b9d341a1c41', 'Physics': '9e368ed4-4fab-41f1-b19c-efa90f86adeb', 'Quantum Physics': '65a0b631-bb6d-42b8-8bab-3c555cce4437', 'Quantitative Biology': '0b695469-3694-4b78-beb3-cc74f2170b09', 'Quantitative Finance': '16e1bcbb-1e33-4fe7-98b7-f8415de48796', 'Statistics': '64fa12fe-ac47-4be4-895d-324127704f45'}\n"
     ]
    }
   ],
   "source": [
    "archives_with_uuids_dict = get_ids_of_archives()\n",
    "print(archives_with_uuids_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categories(categories):\n",
    "    \n",
    "    archives_with_uuids_dict = get_ids_of_archives()\n",
    "    \n",
    "    # add categories to weaviate\n",
    "    batch = weaviate.ThingsBatchRequest()\n",
    "\n",
    "    categories_copy = categories\n",
    "    category_ids = []\n",
    "\n",
    "    for category in categories_copy:\n",
    "        category_copy = copy.deepcopy(category)\n",
    "        archive_beacon = \"weaviate://localhost/things/\" + archives_with_uuids_dict[category['inArchive']]\n",
    "        category_copy['inArchive'] = [{\n",
    "            \"beacon\": archive_beacon\n",
    "        }]\n",
    "        batch.add_thing(category_copy, \"Category\")\n",
    "\n",
    "        # also create archive for the category archive if not exist yet (e.g. \"cs\" for the category id \"cs.AI\"), because some items are labeled wrong in the dataset\n",
    "\n",
    "        # check if archive exists\n",
    "        if (category['id'].split('.')[0] not in category_ids) and (category['id'].split('.')[0] != category['id']):\n",
    "            category_ids.append(category['id'].split('.')[0])\n",
    "\n",
    "            extra_category = {}\n",
    "            extra_category[\"name\"] = category['inArchive']\n",
    "            extra_category[\"id\"] = category['id'].split('.')[0]\n",
    "            extra_category['inArchive'] = [{\n",
    "                \"beacon\": archive_beacon\n",
    "            }]\n",
    "\n",
    "            batch.add_thing(extra_category, \"Category\")\n",
    "\n",
    "    client.batch.create_things(batch)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_categories(categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
